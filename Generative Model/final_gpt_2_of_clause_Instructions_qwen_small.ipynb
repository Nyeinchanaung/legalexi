{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2a91b1-cd24-4f6c-a1ad-a4cd824478ed",
   "metadata": {
    "id": "7e2a91b1-cd24-4f6c-a1ad-a4cd824478ed",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22ef3850-47a5-4eb9-ebfe-5c8bf85e4692"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft accelerate datasets sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/_NLP/_NLP_Project/ModelTraining')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E32IYLDu2xFE",
    "outputId": "9ac5b669-b752-4b4d-e0bf-b2ea2e3a754a"
   },
   "id": "E32IYLDu2xFE",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Qwen"
   ],
   "metadata": {
    "id": "EFpUkxeeZusx"
   },
   "id": "EFpUkxeeZusx"
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Imports ---\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ],
   "metadata": {
    "id": "DsBdi6qWmn8L"
   },
   "id": "DsBdi6qWmn8L",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 2. Load Dataset ---\n",
    "dataset = load_dataset(\"NebulaSense/Legal_Clause_Instructions\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# --- 3. Load GPT-2 Model and Tokenizer (Fix pad_token) ---\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # \u2705 Fix\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=gpt2_tokenizer.eos_token_id)\n"
   ],
   "metadata": {
    "id": "WZZq3AO7e2wE"
   },
   "id": "WZZq3AO7e2wE",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 4. Preprocessing Function ---\n",
    "max_seq_length = 512\n",
    "\n",
    "def preprocess_function(example):\n",
    "    instruction = example['Instruction']\n",
    "    input_field = example.get('Input', None)\n",
    "    output_field = example['Output']\n",
    "\n",
    "    if input_field:\n",
    "        input_text = instruction + \"\\n\" + input_field\n",
    "    else:\n",
    "        input_text = instruction\n",
    "\n",
    "    # For Causal LM: input = prompt + expected output\n",
    "    full_text = input_text + \"\\n\" + output_field\n",
    "\n",
    "    model_inputs = gpt2_tokenizer(\n",
    "        full_text,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": model_inputs[\"input_ids\"].squeeze(0),\n",
    "        \"attention_mask\": model_inputs[\"attention_mask\"].squeeze(0),\n",
    "        \"labels\": model_inputs[\"input_ids\"].squeeze(0).clone()\n",
    "    }\n",
    "\n",
    "# --- 5. Tokenize Datasets ---\n",
    "tokenized_train = train_dataset.map(preprocess_function, remove_columns=train_dataset.column_names)\n",
    "tokenized_test = test_dataset.map(preprocess_function, remove_columns=test_dataset.column_names)"
   ],
   "metadata": {
    "id": "nAdwQa-I6R0E",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "13d27ecd10b74902be046bdb829db9ba",
      "ebf29b386b4d4b858e037af29a5ca6cf",
      "5177bc1190f04f12a3e8b83efcedddb5",
      "12699baf29ad4005b54e6d3d55217af0",
      "4636ec2dad004ed291ec8e9ae62e6fd9",
      "29d98e44603c4feeb34097e8992cb112",
      "c26d31ef1ce3457c8150ecf86a6644be",
      "00cd13a844b24489bab391bf5d87a591",
      "9f0f6f202b8a49c1b1191c1faa5ae8b7",
      "54d6dde33d8846cb8c02ae6a26b48859",
      "d59081929e0844289f20cf3b45a20cf6",
      "23a3a42629a54c9287bc3eb50e66dfaa",
      "c575e1c20d4146b095e29333df1c5e2f",
      "d8d8ccd3929e484aa52e57b7198e6834",
      "075da0e2e2704fb8bd7836613ebf22ab",
      "52806ea3318141f384308614fa2e1372",
      "39e04595af3d4a45a89ae733b89f3893",
      "48cd1be1ce384e30b4b245185779b32d",
      "83226d1b45514854ba103634007b196c",
      "344b32c895ff44ac855765b1060e7a61",
      "e2ee8da24097408a9ae8b93a5912b8d3",
      "781a5f0b7dd84079b3139a81bff6d1aa"
     ]
    },
    "outputId": "f376431b-23e3-4fc4-e380-34449392e671"
   },
   "id": "nAdwQa-I6R0E",
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4557 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13d27ecd10b74902be046bdb829db9ba"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/507 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23a3a42629a54c9287bc3eb50e66dfaa"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bert_score"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfPwcJjcQpub",
    "outputId": "00d26675-8467-4c15-a919-0580f7689cf1"
   },
   "id": "KfPwcJjcQpub",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.51.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 6. Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_legal_outputs\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "# --- 7. Define Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=gpt2_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=gpt2_tokenizer,\n",
    ")\n",
    "\n",
    "# --- 8. Train ---\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "fx1vw-kS6XfW",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "f790d6f3-58cd-4cd8-ccd3-dc13db915977"
   },
   "id": "fx1vw-kS6XfW",
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-23-977481bd47ea>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3420' max='3420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3420/3420 03:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.683700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.568700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.488700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.459300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.381400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.368900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3420, training_loss=0.47800258711764687, metrics={'train_runtime': 232.2804, 'train_samples_per_second': 58.856, 'train_steps_per_second': 14.724, 'total_flos': 3572123369472000.0, 'train_loss': 0.47800258711764687, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 1. Load dataset\n",
    "dataset = load_dataset(\"NebulaSense/Legal_Clause_Instructions\")\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. Prepare input texts\n",
    "input_texts = []\n",
    "reference_outputs = []\n",
    "\n",
    "for example in test_dataset:\n",
    "    instr_type = example[\"Instruction_Type\"]\n",
    "    instruction = example[\"Instruction\"]\n",
    "    input_field = example.get(\"Input\", None)\n",
    "\n",
    "    if instr_type not in [\"generation\", \"modification\"]:\n",
    "        continue\n",
    "\n",
    "    prompt = get_instruction_prompt(instr_type, instruction, input_field)\n",
    "\n",
    "    if prompt and example[\"Output\"]:\n",
    "        input_texts.append(prompt)\n",
    "        reference_outputs.append(example[\"Output\"])\n"
   ],
   "metadata": {
    "id": "nO_3HFgsV9Rt"
   },
   "id": "nO_3HFgsV9Rt",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 16\n",
    "generated_texts = []\n",
    "\n",
    "\n",
    "batches = [input_texts[i:i+batch_size] for i in range(0, len(input_texts), batch_size)]\n",
    "\n",
    "for batch in tqdm(batches, desc=\"Batch Generating...\"):\n",
    "\n",
    "    inputs = gpt2_tokenizer(\n",
    "        batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1,\n",
    "            no_repeat_ngram_size=4,\n",
    "            pad_token_id=gpt2_tokenizer.eos_token_id,\n",
    "            eos_token_id=gpt2_tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "\n",
    "    batch_preds = gpt2_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    for idx, pred_text in enumerate(batch_preds):\n",
    "        prompt = batch[idx]\n",
    "        if pred_text.lower().startswith(prompt.lower().strip()):\n",
    "            pred_text = pred_text[len(prompt):].strip()\n",
    "        generated_texts.append(pred_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUuatW7qWDel",
    "outputId": "b889824d-ad3f-4219-93ff-c64578b3f93e"
   },
   "id": "iUuatW7qWDel",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Batch Generating...:   0%|          | 0/32 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:   3%|\u258e         | 1/32 [00:15<07:55, 15.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:   6%|\u258b         | 2/32 [00:29<07:23, 14.78s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:   9%|\u2589         | 3/32 [00:44<07:02, 14.55s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  12%|\u2588\u258e        | 4/32 [00:58<06:44, 14.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  16%|\u2588\u258c        | 5/32 [01:11<06:20, 14.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  19%|\u2588\u2589        | 6/32 [01:26<06:11, 14.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  22%|\u2588\u2588\u258f       | 7/32 [01:40<05:53, 14.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  25%|\u2588\u2588\u258c       | 8/32 [01:53<05:29, 13.71s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  28%|\u2588\u2588\u258a       | 9/32 [02:06<05:13, 13.64s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  31%|\u2588\u2588\u2588\u258f      | 10/32 [02:21<05:10, 14.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  34%|\u2588\u2588\u2588\u258d      | 11/32 [02:35<04:55, 14.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  38%|\u2588\u2588\u2588\u258a      | 12/32 [02:49<04:39, 13.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  41%|\u2588\u2588\u2588\u2588      | 13/32 [03:02<04:22, 13.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  44%|\u2588\u2588\u2588\u2588\u258d     | 14/32 [03:17<04:12, 14.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  47%|\u2588\u2588\u2588\u2588\u258b     | 15/32 [03:32<04:03, 14.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  50%|\u2588\u2588\u2588\u2588\u2588     | 16/32 [03:46<03:46, 14.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 17/32 [04:00<03:35, 14.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 18/32 [04:14<03:18, 14.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 19/32 [04:29<03:08, 14.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 20/32 [04:44<02:53, 14.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 21/32 [04:58<02:37, 14.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 22/32 [05:13<02:24, 14.48s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 23/32 [05:26<02:08, 14.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 24/32 [05:41<01:55, 14.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 25/32 [05:55<01:40, 14.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 26/32 [06:10<01:25, 14.33s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 27/32 [06:23<01:10, 14.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 28/32 [06:37<00:55, 13.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 29/32 [06:52<00:42, 14.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 30/32 [07:07<00:28, 14.45s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 31/32 [07:20<00:14, 14.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Batch Generating...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 32/32 [07:31<00:00, 14.12s/it]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(generated_texts, reference_outputs, lang=\"en\", verbose=True)\n",
    "\n",
    "print(f\"Precision: {P.mean().item():.4f}\")\n",
    "print(f\"Recall: {R.mean().item():.4f}\")\n",
    "print(f\"F1: {F1.mean().item():.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "50ae5fe8c045481fb861021885bde36c",
      "cfbadb2c66f7477bb201309eb8b65286",
      "58c351acc4704f03972b3b397aad757e",
      "c3ae482dbacd4a348bcb447f9feb6aac",
      "542c2d34201346fb95967d44e6c55202",
      "354eae41784847f9b03aedb95d2b9259",
      "0458472d63a241f38f1a06bd9ddefccb",
      "b4d1cc6420d141c19b8f50c1d0acb8cb",
      "5b8d98f5ed704ddd95522dc8abd6227a",
      "8f864723b2114424a7bceaeeea280bc0",
      "682690968bc34165b7c1a4e77e1b7393",
      "62a43519c08b4352b210ad74c819b908",
      "4ae795b002c1488991951da890719eee",
      "2eb007c6c410415ba001a425b053ef9b",
      "cd06ec580ad546cfb01a99492d103df4",
      "ac28d323846e4cb3b131a40e2ed77cdb",
      "46d092a2267241e0b49860f67584e10e",
      "d88140ad27944be8862c3c574cbb2570",
      "ab57adde85f842579c526ae27a4ec3c1",
      "f4b684681f5849c7a070ca45009729d6",
      "626dd14154ba4e6cb8fb34a1c15e0069",
      "c2f78378e1694dbeb74cbe142b3f6f0d",
      "971ac86d346e41c69d4ae2a8bcff815b",
      "31cc9b5db78740aab008c3e51368c714",
      "2ef23d2503994699b818ca6ec63a3fb3",
      "8ed95fec9bea4eb2a51367c8a88d0c18",
      "0103f38cf83b4f22ae0ec1d5b8d56ec2",
      "db45a10129c64a5ea910275564968530",
      "48729812f8394b3b8d922b1f83a646ff",
      "d78fe861cb62477c850a0e50f8d9ba1c",
      "20d596fc98404f089a801efe8a399fdf",
      "b97c5ee8cb7d4551a328f1b09a0d803e",
      "644191c116434843949a145260527425",
      "c8246ba6af4c4015bb3ce6e011bce5e6",
      "097701e34e77400e9013d28b37b29a75",
      "e4d39f1f2c67471085951e3640145a00",
      "d7c13378d3e7449d933316135cbcee63",
      "13a8e3e12eab4f4e95f93d0de470d012",
      "5a3283e84c914879add5f57c5eb927fe",
      "44312f461be344b38d22e6b3754ff57f",
      "d2149a5f2b034b0ba80536ccb2bda563",
      "841dde22b01641b59f68c5dc5d708fba",
      "2145f00c702749cf896c89d474443df2",
      "e89c07973897485aa5328980f09fb118",
      "e0fb83844d224582aecce8eb3959acab",
      "c3c1908fb2e24fd6aa0fc2ebf8261c73",
      "9406ef73368e4a5caedb068df757360c",
      "d40b223d3ca746bb92c0e6dca60b6785",
      "8434a656c5a140dc8818b99da80e30cb",
      "8cb83f823f2f4cf4a52355580b5aa7aa",
      "3948d6457af34bb2af6220efb0456fa1",
      "40ade901b74146819370d8efdd50e1ef",
      "732cde55e4d3422897e5fc9c2dc68e22",
      "0e0cdaf52c7c4b7393ff2e5617242dfc",
      "a12d62460c2541d8bd0fd3c381293409",
      "c5e1d7512911471fa1d0da014583a6d5",
      "aa655f0af5584f0faea9b91ea675a700",
      "6d91f68b05984ba095cb38cfc4593344",
      "0017d9be6016497f8fc3bbf7a93818dd",
      "f46f61b278974b4c8d3f06b461e15411",
      "e3838c1827924fc99d68fa11720ef1af",
      "1bb536f02bab4bdaa00ea22ff858d6d5",
      "6f4ea7eeacfb4f8a9e17a4f687627a24",
      "d0f8834a4997450aa3d282acd8dbd9f0",
      "91f50ad47915468b9dd3992115d008f3",
      "2e0acad2d0934296ba0b190e9fd1bb62",
      "c0e77e9222d34cbeab08b9dc59b9ba26",
      "f4449fcb27f14a92871d8ce677fb2ed9",
      "9c0f022ae3204f9a82d819dd7deba708",
      "9448b4f245394171a1cd6344f5b5883f",
      "3ca6db2d9e654dcd8b56930ea820b7fe",
      "828f9036c91f4955a7966d9fcbf1bb2c",
      "6c3cbc2d43a14a7eb60245f4f72e7f47",
      "ce2711425be74a1284169956ea6ffba5",
      "42ca92203a004542bafdb0072e1b8614",
      "2b4d3429c4044c6cb698fe4089b2cba0",
      "74b5dfc67b8a4a97b5bfb5c4f1c6bda7",
      "1a6d26dce81a4260994f03397b4e0f32",
      "784be14846af45cb9743396ca92b19e7",
      "b5c1f34f645942abb36a0157e6cdc53e",
      "b6c04abe484a4f51bb90909f27b05782",
      "29ec57a537394c9a9a3f016cb70bf8ec",
      "fe4565612d4d4e8ca48d448f3e4dc47c",
      "fc08d282eafe49dc8a39739b0549aed8",
      "b678ed4a4f5148b6a257071a05ca35a4",
      "b5e0c2c74d5c47de9106b71e07fb0327",
      "01aa536ac5f2450fa7c9e908b2a359d6",
      "896d341e93734668b74fd88e6f4d2548"
     ]
    },
    "id": "Op1LU0NLWEBN",
    "outputId": "a13ac6ea-abde-4a56-fac6-9dbfe353e109"
   },
   "id": "Op1LU0NLWEBN",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50ae5fe8c045481fb861021885bde36c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a43519c08b4352b210ad74c819b908"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "971ac86d346e41c69d4ae2a8bcff815b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8246ba6af4c4015bb3ce6e011bce5e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0fb83844d224582aecce8eb3959acab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5e1d7512911471fa1d0da014583a6d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0e77e9222d34cbeab08b9dc59b9ba26"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a6d26dce81a4260994f03397b4e0f32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done in 19.02 seconds, 26.65 sentences/sec\n",
      "Precision: 0.7315\n",
      "Recall: 0.7936\n",
      "F1: 0.7608\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "l99V75ltg2mR"
   },
   "id": "l99V75ltg2mR",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}